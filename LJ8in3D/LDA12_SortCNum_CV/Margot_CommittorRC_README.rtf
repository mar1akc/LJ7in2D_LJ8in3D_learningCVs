{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww20280\viewh18140\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs36 \cf0 \expnd0\expndtw0\kerning0
class LJ8_3(nn.Module):\
\'a0 \'a0 """Feedfoward neural network with 2 hidden layer"""\
\'a0 \'a0 def __init__(self, in_size, hidden_size,hidden_size2, out_size):\
\'a0 \'a0 \'a0 \'a0 super().__init__()\
\'a0 \'a0 \'a0 \'a0 # 1st hidden layer\
\'a0 \'a0 \'a0 \'a0 self.linear1 = nn.Linear(in_size, hidden_size)\
\'a0 \'a0 \'a0 \'a0 # 2nd hidden layer\
\'a0 \'a0 \'a0 \'a0 self.linear2 = nn.Linear(hidden_size,hidden_size2)\
\'a0 \'a0 \'a0 \'a0 self.linear3 = nn.Linear(hidden_size2,hidden_size2)\
\'a0 \'a0 \'a0 \'a0 # output layer\
\'a0 \'a0 \'a0 \'a0 self.linear4 = nn.Linear(hidden_size2, out_size)\
\'a0 \'a0 \'a0 \'a0 \
\'a0 \'a0 def forward(self, xb):\
\'a0 \'a0 \'a0 \'a0 # Get information from the data\
\'a0 \'a0 \'a0 \'a0 # Get intermediate outputs using hidden layer\
\'a0 \'a0 \'a0 \'a0 out = self.linear1(xb)\
\'a0 \'a0 \'a0 \'a0 # Apply activation function\
\'a0 \'a0 \'a0 \'a0 relu = nn.ReLU()\
\'a0 \'a0 \'a0 \'a0 out = relu(out)\
\'a0 \'a0 \'a0 \'a0 # Get predictions using output layer\
\'a0 \'a0 \'a0 \'a0 out = self.linear2(out)\
\'a0 \'a0 \'a0 \'a0 # apply activation function again\
\'a0 \'a0 \'a0 \'a0 out = relu(out)\
\'a0 \'a0 \'a0 \'a0 # last hidden layer \
\'a0 \'a0 \'a0 \'a0 out = self.linear3(out)\
\'a0 \'a0 \'a0 \'a0 \
\'a0 \'a0 \'a0 \'a0 out = relu(out)\
\'a0 \'a0 \'a0 \'a0 # last hidden layer \
\'a0 \'a0 \'a0 \'a0 out = self.linear4(out)\
\'a0 \'a0 \'a0 \'a0 \
\'a0 \'a0 \'a0 \'a0 #sigmoid function\
\'a0 \'a0 \'a0 \'a0 out = torch.sigmoid(out)\
\'a0 \'a0 \'a0 \'a0 return out
\fs24 \
}